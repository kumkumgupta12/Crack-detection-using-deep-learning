{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "damage_detection_using_unet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnu921/damage_detection_using_deep_learning/blob/main/damage_detection_using_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Lg5GaQj2rQOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "print(\"Python version:\", platform.python_version())\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"tensorflow version:\",tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "print(\"numpy version:\",np.__version__)\n",
        "\n",
        "import cv2\n",
        "print(\"cv2 version:\",cv2.__version__)\n",
        "\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "print(\"matplotlib version:\",matplotlib.__version__)\n",
        "\n",
        "import pandas as pd\n",
        "print(\"pandas version:\",pd.__version__)\n",
        "\n",
        "from skimage.transform import resize\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bCTMrKA_t3q",
        "outputId": "91a6869c-5f90-434c-b93a-ac62a04d5d41"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.7.13\n",
            "tensorflow version: 2.8.2\n",
            "numpy version: 1.21.6\n",
            "cv2 version: 4.1.2\n",
            "matplotlib version: 3.2.2\n",
            "pandas version: 1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the necessary Keras libraries for Creating the U-Net Model with gated attention and residual connections\n",
        "\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, Add, Dropout, UpSampling2D, Input, Multiply, MaxPooling2D, Concatenate, concatenate, AveragePooling2D, Lambda, Conv2DTranspose, Reshape, ZeroPadding2D, MaxPool2D\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "3_Jeaclu9UwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_ds = os.path.join('/content/drive/MyDrive/IC-SHM 2021','Tokaido_dataset') #put a path to the dataset"
      ],
      "metadata": {
        "id": "COiQH2y_GRYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to change the path format \n",
        "def path_correct(path):\n",
        "  path = '/'.join(path[2:].split('\\\\'))\n",
        "  path = os.path.join(path_ds, path)\n",
        "  return path"
      ],
      "metadata": {
        "id": "SD4fgF2PDv3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to put the label images into 3 channels\n",
        "def get_label(file_path):\n",
        "  \n",
        "    mask = np.squeeze(file_path, axis = 2)\n",
        "    target_array = np.zeros((mask.shape[0],mask.shape[1],3))\n",
        "    target_array[:,:,0]=np.where(mask == 1, 1, 0)\n",
        "    target_array[:,:,1]=np.where(mask == 2, 1, 0)\n",
        "    target_array[:,:,2]=np.where(mask == 3, 1, 0)\n",
        "    \n",
        "    return target_array"
      ],
      "metadata": {
        "id": "3VwS0byvED-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to plot the images and labels\n",
        "def show_img(image):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "\n",
        "def show_label(label):\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(16, 112))\n",
        "  y1 = label[:,:,0]\n",
        "  y2 = label[:,:,1]\n",
        "  y3 = label[:,:,2]\n",
        "  plt.axis('off')\n",
        "  axes[0].axis('off')\n",
        "  axes[1].axis('off')\n",
        "  axes[2].axis('off')\n",
        "  axes[0].imshow(y1)\n",
        "  axes[1].imshow(y2)\n",
        "  axes[2].imshow(y3)"
      ],
      "metadata": {
        "id": "7TojCiTJFzQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print the prediction images\n",
        "def show_pred(y):\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(16, 112))\n",
        "  y1 = y[:,:,0]\n",
        "  y2 = y[:,:,1]\n",
        "  y3 = y[:,:,2]\n",
        "  plt.axis('off')\n",
        "  axes[0].axis('off')\n",
        "  axes[1].axis('off')\n",
        "  axes[2].axis('off')\n",
        "  axes[0].imshow(y1)\n",
        "  axes[1].imshow(y2)\n",
        "  axes[2].imshow(y3)"
      ],
      "metadata": {
        "id": "Y1leMYHeFz5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to normalize the images\n",
        "def normalize(input_image):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  return input_image"
      ],
      "metadata": {
        "id": "XDS6SDj0F6IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image and Label augmentation function \n",
        "def image_augmentation(img):\n",
        "  seed = (2,3)\n",
        "  img = tf.image.stateless_random_flip_left_right(img, seed) \n",
        "  return img\n",
        "\n",
        "def label_augmentation(img):\n",
        "  seed = (2,3)\n",
        "  img = tf.image.stateless_random_flip_left_right(img, seed)\n",
        "  return img"
      ],
      "metadata": {
        "id": "3N7jX-W_F6sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess function to run all the required preprocessing functions on the images\n",
        "def preprocess(x, y):\n",
        "    def f(x, y):\n",
        "        x = tf.io.read_file(x)\n",
        "        y = tf.io.read_file(y)\n",
        "        x = tf.io.decode_png(x, channels = 3)\n",
        "        x = tf.image.resize_with_pad(x, 256, 448)\n",
        "        x = tf.numpy_function(normalize, [x], [tf.float32])\n",
        "        y = tf.io.decode_bmp(y, channels = 0)\n",
        "        y = tf.numpy_function(get_label, [y], [tf.float32])\n",
        "        y = tf.image.resize_with_pad(y, 256, 448)\n",
        "        x = tf.numpy_function(image_augmentation, [x], [tf.float32])\n",
        "        y = tf.numpy_function(label_augmentation, [y], [tf.float32])\n",
        "        \n",
        "        return x, y\n",
        "\n",
        "    images, masks = tf.numpy_function(f, [x, y], [tf.float32, tf.float32])\n",
        "    images.set_shape([256, 448, 3])\n",
        "    masks.set_shape([256, 448, 3])\n",
        "\n",
        "    return images, masks"
      ],
      "metadata": {
        "id": "SjlpSj59GAEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data pipeline function to cache dataset to ram for reducing the data loading bottleneck during training\n",
        "def tf_dataset(x, y, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.shuffle(buffer_size=1800)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls= tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch, num_parallel_calls= tf.data.AUTOTUNE)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.cache()\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "6IOIETYTGESc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the training data for damage images\n",
        "#Access the csv file containing the absolute directory paths to each file\n",
        "\n",
        "col_names = ['image file name', 'component label file name', 'damage label file name', 'depth image file name', \n",
        "             'camera focal length in mm', 'regular images', 'images containing damage in the RRDR']\n",
        "ftrain = pd.read_csv(os.path.join(path_ds,'files_train.csv'),names = col_names,delimiter=',')\n",
        "ftrain.iloc[:,0] = ftrain.iloc[:,0].apply(lambda x: path_correct(x))\n",
        "ftrain.iloc[:,1] = ftrain.iloc[:,1].apply(lambda x: path_correct(x))\n",
        "ftrain.iloc[:,2] = ftrain.iloc[:,2].apply(lambda x: path_correct(x))\n",
        "ftrain.iloc[:,3] = ftrain.iloc[:,3].apply(lambda x: path_correct(x))\n",
        "train_comp = ftrain.loc[ftrain['regular images']==True, ['image file name', 'component label file name', 'damage label file name', 'depth image file name', 'camera focal length in mm']]\n",
        "train_dmg = ftrain.loc[ftrain['images containing damage in the RRDR']==True, ['image file name', 'component label file name', 'damage label file name', 'depth image file name', 'camera focal length in mm']]\n"
      ],
      "metadata": {
        "id": "HZAjzoEWGMP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dmg"
      ],
      "metadata": {
        "id": "lWgA_koMYFlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the training image\n",
        "\n",
        "#image\n",
        "print(ftrain.iloc[3])\n",
        "image = mpimg.imread(ftrain.iloc[3][0])\n",
        "print(image.shape)\n",
        "print(type(image))\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "elozNv5dcPNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#label\n",
        "#Printing the above image label\n",
        "print(ftrain.iloc[3])\n",
        "image = mpimg.imread(ftrain.iloc[3][2])#[x][y] x = row no. & y = {0:raw image, 1:component label, 2:damage label, 3:depth label}\n",
        "print(image.shape)\n",
        "print(type(image))\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "Cj7ooi34ciDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the training data from the pure_tex file\n",
        "\n",
        "#Access the csv file containing the absolute directory paths to each file\n",
        "\n",
        "col_names = ['image file name', 'damage label file name']\n",
        "\n",
        "ftrain_tex = pd.read_csv(os.path.join(path_ds,'files_puretex_train.csv'),names = col_names,delimiter=',')\n",
        "ftrain_tex.iloc[:,0] = ftrain_tex.iloc[:,0].apply(lambda x: path_correct(x))\n",
        "ftrain_tex.iloc[:,1] = ftrain_tex.iloc[:,1].apply(lambda x: path_correct(x))\n",
        "\n",
        "train_dmg_tex = ftrain_tex"
      ],
      "metadata": {
        "id": "_FnUMgUwA4Mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dmg_tex"
      ],
      "metadata": {
        "id": "MjUMOhuzY0N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the training image\n",
        "print(ftrain_tex.iloc[2])\n",
        "image = mpimg.imread(ftrain_tex.iloc[2][1])\n",
        "print(image.shape)\n",
        "print(type(image))\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "f60Az-eAcCP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the data for training and validation and also joining the dataset of both texture and component demage\n",
        "\n",
        "#Run for training on the damage images\n",
        "train1 = train_dmg[:1500]\n",
        "val1 = train_dmg[2000:2800]\n",
        "#train1 = train_dmg[:4000]\n",
        "#val1 = train_dmg[4000:]\n",
        "\n",
        "#appending texture images to the training and validation dataset\n",
        "#train1 = train1.append(train_dmg_tex[:2300])\n",
        "#val1 = val1.append(train_dmg_tex[2300:])"
      ],
      "metadata": {
        "id": "W7gduSNIHYpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train1"
      ],
      "metadata": {
        "id": "G6ZpecvoaMFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the tf dataset from dataframe containing image addresses\n",
        "\n",
        "images = train1['image file name'].to_numpy()\n",
        "masks = train1['damage label file name'].to_numpy()\n",
        "dataset = tf_dataset(images, masks)\n",
        "images_val = val1['image file name'].to_numpy()\n",
        "masks_val = val1['damage label file name'].to_numpy()\n",
        "dataset_val = tf_dataset(images_val, masks_val)"
      ],
      "metadata": {
        "id": "vtSF7uHBHZOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing out an image for reference\n",
        "for x, y in dataset.take(2):\n",
        "        show_img(x[0])\n",
        "        show_label(y[0])\n",
        "        \n",
        "        break "
      ],
      "metadata": {
        "id": "sXQLpoJNIMWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number of features to be used in the model df for encoder and uf for decoder, 32 was found to be optimal for both\n",
        "df=32\n",
        "uf=32\n",
        "    \n",
        "def build_unet(input_shape):\n",
        "\n",
        "  # E-Res Layer\n",
        "  def eres_block(inputs, num_filters=32):\n",
        "\n",
        "    x1 = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation(\"relu\")(x1)\n",
        "\n",
        "    x2 = Conv2D(num_filters, 3, padding=\"same\")(x1)\n",
        "    x2 = BatchNormalization()(x2)\n",
        "    x2 = Activation(\"relu\")(x2)\n",
        "\n",
        "    x3 = Conv2D(num_filters, 3, padding=\"same\")(x2)\n",
        "    x3 = BatchNormalization()(x3)\n",
        "    x3 = Activation(\"relu\")(x3)\n",
        "\n",
        "    sc = Conv2D(num_filters, 1, padding=\"same\")(inputs)\n",
        "    sc = BatchNormalization()(sc)\n",
        "    sc = Activation(\"relu\")(sc)\n",
        "\n",
        "    # x4 = Concatenate(axis=3)([x1, x2, x3])\n",
        "\n",
        "    rp = Add()([sc, x3])\n",
        "    rp = Activation('relu')(rp)\n",
        "\n",
        "    return rp\n",
        "\n",
        "  # E-Res Path for skip connection\n",
        "  def eres_path(inputs, num_filters):\n",
        "    \n",
        "    for i in range(1):\n",
        "      x1 = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "      x1 = BatchNormalization()(x1)\n",
        "      x1 = Activation(\"relu\")(x1)\n",
        "\n",
        "      x2 = Conv2D(num_filters, 1, padding=\"same\")(inputs)\n",
        "      x2 = BatchNormalization()(x2)\n",
        "      x2 = Activation(\"relu\")(x2)\n",
        "\n",
        "      inputs = Add()([x1, x2])\n",
        "      inputs = Activation('relu')(inputs)\n",
        "    \n",
        "    return inputs\n",
        "\n",
        "  # Dilated Convolution Module\n",
        "  def dcm(inputs, num_filters):\n",
        "\n",
        "    x = Conv2D(num_filters, 1, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x1 = Conv2D(num_filters, 3, dilation_rate=1 , padding=\"same\")(x)\n",
        "    x1 = BatchNormalization()(x1)\n",
        "    x1 = Activation(\"relu\")(x1)\n",
        "\n",
        "    x2 = Conv2D(num_filters, 3, dilation_rate=2 , padding=\"same\")(x)\n",
        "    x2 = BatchNormalization()(x2)\n",
        "    x2 = Activation(\"relu\")(x2)\n",
        "\n",
        "    x3 = Conv2D(num_filters, 3, dilation_rate=3 , padding=\"same\")(x)\n",
        "    x3 = BatchNormalization()(x3)\n",
        "    x3 = Activation(\"relu\")(x3)\n",
        "\n",
        "    x4 = Add()([x1, x2, x3])\n",
        "    x4 = Activation(\"relu\")(x4)\n",
        "    \n",
        "    res = Conv2D(num_filters, 1, padding=\"same\")(x4)\n",
        "    res = BatchNormalization()(res)\n",
        "    res = Activation(\"relu\")(res)\n",
        "\n",
        "    return res\n",
        "    \n",
        "\n",
        "  # encoder block\n",
        "  def encoder_block(input, num_filters):\n",
        "    x = eres_block(input, num_filters)\n",
        "    x = eres_path(x, num_filters)\n",
        "    p = MaxPool2D((2,2))(x)\n",
        "    return x, p\n",
        "\n",
        "  # Decoder block\n",
        "  def decoder_block(input, skip_features, num_filters):\n",
        "      x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "      x = Concatenate()([x, skip_features])\n",
        "      x = eres_block(x, num_filters)\n",
        "      return x\n",
        "\n",
        "\n",
        "  #actual model definition depth = 4, i.e. 4 times downsampled by factor of 2 (by maxpooling)\n",
        "\n",
        "  inputs = Input(input_shape)\n",
        "    \n",
        "  s1, p1 = encoder_block(inputs, 64)\n",
        "\n",
        "  s2, p2 = encoder_block(p1, 128)\n",
        "\n",
        "  s3, p3 = encoder_block(p2, 256)\n",
        "\n",
        "  s4 = dcm(p3, 512)\n",
        "\n",
        "  d1 = decoder_block(s4, s3, 256)\n",
        "\n",
        "  d2 = decoder_block(d1, s2, 128)\n",
        "\n",
        "  d3 = decoder_block(d2, s1, 64)\n",
        "\n",
        "  #here the first input to Conv2D i.e. 3 defines the output number of classes to be pridicted\n",
        "\n",
        "  outputs = Conv2D(3,kernel_size=(1,1),strides=(1,1),activation='sigmoid')(d3)\n",
        "   \n",
        "  model = Model(inputs=inputs,outputs=outputs)\n",
        "    \n",
        "  return model"
      ],
      "metadata": {
        "id": "vNplJOeDIjIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the unet model with gated attention and residual connections and printing its summary\n",
        "model = build_unet((256,448,3))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "DUj7bZlCIkHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using Adam optimizer and fixing the learning rate \n",
        "optimizer_adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)"
      ],
      "metadata": {
        "id": "NWUafFDpInP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checkpoint for model saving and reloading the saved weights\n",
        "# \"training_dmg_resatt_final/cp_dmg.ckpt\" this checkpoint to be supplied for best weights as trained by us\n",
        "ck_path = os.path.join('/content/drive/MyDrive/summer_intern','eres_damage_cps')\n",
        "checkpoint_path = os.path.join(ck_path, \"my_checkpoint.ckpt\")\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,  monitor = 'iou', mode='max', save_best_only = True,\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "id": "osS-nF3QIsSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Courtesy stackoverflow Daniel Möller https://stackoverflow.com/users/2097240/daniel-m%c3%b6ller?tab=profile\n",
        "answer to question 'Custom loss function for U-net in keras using class weights: `class_weight` not supported for 3+ dimensional targets' \n",
        "\"\"\"\n",
        "# Weighted loss function \n",
        "def weightedLoss(originalLossFunc, weightsList):\n",
        "\n",
        "    def lossFunc(true, pred):\n",
        "\n",
        "        axis = -1 #if channels last \n",
        "        #axis=  1 #if channels first\n",
        "\n",
        "\n",
        "        #argmax returns the index of the element with the greatest value\n",
        "        #done in the class axis, it returns the class index    \n",
        "        classSelectors = K.argmax(true, axis=axis)\n",
        "        classSelectors = tf.cast(classSelectors, tf.int32) \n",
        "            #if your loss is sparse, use only true as classSelectors\n",
        "\n",
        "        #considering weights are ordered by class, for each class\n",
        "        #true(1) if the class index is equal to the weight index   \n",
        "        classSelectors = [K.equal(i, classSelectors) for i in range(len(weightsList))]\n",
        "\n",
        "        #casting boolean to float for calculations  \n",
        "        #each tensor in the list contains 1 where ground true class is equal to its index \n",
        "        #if you sum all these, you will get a tensor full of ones. \n",
        "        classSelectors = [K.cast(x, K.floatx()) for x in classSelectors]\n",
        "\n",
        "        #for each of the selections above, multiply their respective weight\n",
        "        weights = [sel * w for sel,w in zip(classSelectors, weightsList)] \n",
        "\n",
        "        #sums all the selections\n",
        "        #result is a tensor with the respective weight for each element in predictions\n",
        "        weightMultiplier = weights[0]\n",
        "        for i in range(1, len(weights)):\n",
        "            weightMultiplier = weightMultiplier + weights[i]\n",
        "\n",
        "\n",
        "        #make sure your originalLossFunc only collapses the class axis\n",
        "        #you need the other axes intact to multiply the weights tensor\n",
        "        loss = originalLossFunc(true,pred) \n",
        "        loss = loss * weightMultiplier\n",
        "\n",
        "        return loss\n",
        "    return lossFunc"
      ],
      "metadata": {
        "id": "OQ54omADIyMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summation of dice loss and cross entropy loss\n",
        "\n",
        "from keras import backend as K\n",
        "def DiceCELoss(targets, inputs, smooth=1e-6):\n",
        "    CE = tf.keras.metrics.binary_crossentropy(targets, inputs)\n",
        "    y_true_f=K.flatten(targets)\n",
        "    y_pred_f=K.flatten(inputs)\n",
        "    intersection=K.sum(y_true_f*y_pred_f)\n",
        "    dice_loss=1-((2*intersection) + smooth)/(K.sum(y_true_f*y_true_f)+K.sum(y_pred_f*y_pred_f)+ smooth)\n",
        "    dice_CE=dice_loss+CE\n",
        "    return dice_CE"
      ],
      "metadata": {
        "id": "4ukfchGpIy5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summation of log of (1-dice loss) and cross entropy loss\n",
        "\n",
        "import math\n",
        "from keras import backend as K\n",
        "def logDiceCELoss(targets, inputs, smooth=1e-6):\n",
        "    CE = tf.keras.metrics.binary_crossentropy(targets, inputs)\n",
        "    #CE = tf.keras.metrics.CategoricalCrossentropy(targets, inputs)\n",
        "    y_true_f=K.flatten(targets)\n",
        "    y_pred_f=K.flatten(inputs)\n",
        "    intersection=K.sum(y_true_f*y_pred_f)\n",
        "    dice_loss=1-((2*intersection) + smooth)/(K.sum(y_true_f*y_true_f)+K.sum(y_pred_f*y_pred_f)+ smooth)\n",
        "    dice_CE=CE-math.log(1-dice_loss)\n",
        "    return dice_CE"
      ],
      "metadata": {
        "id": "K5cC1H-DJ6Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The weights for each class are hardcoded here and are calculated using the code presented towards the end of this notebook\n",
        "w1= 0.03611688490088685\n",
        "w2= 1.0\n",
        "w3=9.345573778790564"
      ],
      "metadata": {
        "id": "5UHFQ8e_J9Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best results were obtained with binary cross entropy loss\n",
        "\n",
        "model.compile(optimizer= optimizer_adam,\n",
        "              loss= weightedLoss(tf.keras.losses.BinaryCrossentropy(), [w1,w2,w3]),\n",
        "              metrics=[\n",
        "                       tf.keras.metrics.BinaryAccuracy(),\n",
        "                       tf.keras.metrics.Recall(thresholds = 0.2),\n",
        "                       tf.keras.metrics.Precision(thresholds = 0.7),\n",
        "                       tf.keras.metrics.MeanIoU(3,name=\"iou\")])"
      ],
      "metadata": {
        "id": "buvG1SNWKCPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run this cell for loading the weights from saved checkpoints\n",
        "model.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "K5l8n8e4KC9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training, Metrics and Validation**"
      ],
      "metadata": {
        "id": "wH7g2uOHLEk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "history = model.fit(dataset, epochs= 20 ,validation_data= dataset_val, verbose = 1, callbacks=[cp_callback])"
      ],
      "metadata": {
        "id": "-arJPG2tKI9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print Loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, loss, 'r', label='Training loss')\n",
        "plt.plot(history.epoch, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ChICOK0oKLIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print Binary Accuracy\n",
        "accu = history.history['binary_accuracy']\n",
        "val_accu = history.history['val_binary_accuracy']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, accu, 'r', label='Training binary accuracy')\n",
        "plt.plot(history.epoch, val_accu, 'b', label='Validation binary accuracy')\n",
        "plt.title('Training and Validation binary accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('binary accuracy Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g2vIILzcKL8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print recall\n",
        "recall = history.history['recall']\n",
        "val_recall = history.history['val_recall']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, recall, 'r', label='Training recall')\n",
        "plt.plot(history.epoch, val_recall, 'b', label='Validation recall')\n",
        "plt.title('Training and Validation recall')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('recall Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D92yUGrhKN6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print precision\n",
        "pres = history.history['precision']\n",
        "val_pres = history.history['val_precision']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, pres, 'r', label='Training precision')\n",
        "plt.plot(history.epoch, val_pres, 'b', label='Validation precision')\n",
        "plt.title('Training and Validation precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('precision Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ydaiqzfsKRyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print Mean IoU\n",
        "miou = history.history['iou']\n",
        "val_miou = history.history['val_iou']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.epoch, miou, 'r', label='Training mean_io_u')\n",
        "plt.plot(history.epoch, val_miou, 'b', label='Validation mean_io_u')\n",
        "plt.title('Training and Validation mean_io_u')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('mean_io_u Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CyiM98gPKSre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model on validation dataset\n",
        "model.evaluate(dataset_val, verbose = 1)"
      ],
      "metadata": {
        "id": "zGBjOwwGKV_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing predictions on the validation dataset\n",
        "z=1\n",
        "for x, y in dataset_val.take(10):\n",
        "        z += 1\n",
        "        show_img(x[2])\n",
        "        show_label(y[2])\n",
        "        pred = model.predict(x)\n",
        "        show_pred(pred[2])\n",
        "        if (z==9):\n",
        "          break"
      ],
      "metadata": {
        "id": "hNA_Zm0wKtho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Testing**"
      ],
      "metadata": {
        "id": "_Vdc1GyGK8Gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the labels of texture images for testing (its required for the test dataloader to work)\n",
        "#this function would load the false test data labels for working of data loader only. the false labels arent used there for any actual purpose, this only enables\n",
        "#the data loader to work smoothly\n",
        "def get_label_tex(file_path):\n",
        "    mask = file_path\n",
        "    target_array = np.zeros((mask.shape[0],mask.shape[1],3))\n",
        "    \n",
        "    return target_array"
      ],
      "metadata": {
        "id": "vm3V7_ESzPa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing for the test dataset\n",
        "def preprocess_test(x,y):\n",
        "    def f(x,y):\n",
        "        x = tf.io.read_file(x)\n",
        "        y = tf.io.read_file(y)\n",
        "        x = tf.io.decode_png(x, channels = 3)\n",
        "        x = tf.image.resize_with_pad(x, 256,448)\n",
        "        x = tf.numpy_function(normalize, [x], [tf.float32]) \n",
        "        y = tf.io.decode_png(y, channels = 0)   \n",
        "        y = tf.numpy_function(get_label_tex, [y], [tf.float32])\n",
        "        y = tf.image.resize_with_pad(y, 256, 448)   \n",
        "\n",
        "        return x, y\n",
        "\n",
        "    images, masks = tf.numpy_function(f, [x, y], [tf.float32, tf.float32])\n",
        "    images.set_shape([256, 448, 3])\n",
        "    masks.set_shape([256, 448, 3])\n",
        "\n",
        "    return images, masks"
      ],
      "metadata": {
        "id": "PpoF9iFfK-nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloader for the test dataset\n",
        "def tf_dataset_test(x,y, batch = 8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.map(preprocess_test, num_parallel_calls= tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(batch, num_parallel_calls= tf.data.AUTOTUNE)\n",
        "    dataset = dataset.cache()\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "vB0XwZ3rMdP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to change the path format \n",
        "def path_correct_png(path):\n",
        "  path = '/'.join(path[2:].split('\\\\'))\n",
        "  path = os.path.join(path_ds, path)\n",
        "  path = path[:-4] + '.png'\n",
        "  return path"
      ],
      "metadata": {
        "id": "eePHykyGMeBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the training data from the pure_tex file\n",
        "\n",
        "#Access the csv file containing the absolute directory paths to each file\n",
        "\n",
        "col_names = ['image file name', 'damage label file name']\n",
        "\n",
        "ftest = pd.read_csv(os.path.join(path_ds,'files_puretex_test.csv'),names = col_names,delimiter=',')\n",
        "ftest.iloc[:,0] = ftest.iloc[:,0].apply(lambda x: path_correct(x))\n",
        "ftest.iloc[:,1] = ftest.iloc[:,1].apply(lambda x: path_correct_png(x))\n",
        "\n",
        "test_dmg_tex = ftest"
      ],
      "metadata": {
        "id": "T3p7T1GUMgAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dataloader for texture images\n",
        "images_test = test_dmg_tex['image file name'].to_numpy()\n",
        "masks_test = test_dmg_tex['damage label file name'].to_numpy()\n",
        "dataset_test_tex = tf_dataset_test(images_test,masks_test)\n",
        "address_tex = test_dmg_tex['damage label file name'].apply(lambda x : os.path.split(x)[1]).to_numpy()"
      ],
      "metadata": {
        "id": "MKhOpkRkMlHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing predictions on the texture test dataset\n",
        "z=1\n",
        "for x, y in dataset_test_tex.take(10):\n",
        "        z += 1\n",
        "        show_img(x[2])\n",
        "        show_label(y[2])\n",
        "        pred = model.predict(x)\n",
        "        show_pred(pred[2])\n",
        "        if (z==9):\n",
        "          break"
      ],
      "metadata": {
        "id": "-jExKQf_ZqdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the testing data from the component demage test dataset file\n",
        "\n",
        "#Access the csv file containing the absolute directory paths to each file\n",
        "\n",
        "col_names = ['image file name', 'component label file name', 'damage label file name', 'depth image file name', \n",
        "             'camera focal length in mm', 'regular images', 'images containing damage in the RRDR']\n",
        "ftest = pd.read_csv(os.path.join(path_ds,'files_test.csv'),names = col_names,delimiter=',')\n",
        "ftest.iloc[:,0] = ftest.iloc[:,0].apply(lambda x: path_correct(x))\n",
        "ftest.iloc[:,1] = ftest.iloc[:,1].apply(lambda x: path_correct(x))\n",
        "ftest.iloc[:,2] = ftest.iloc[:,2].apply(lambda x: path_correct_png(x))\n",
        "ftest.iloc[:,3] = ftest.iloc[:,3].apply(lambda x: path_correct(x))\n",
        "test_comp = ftest.loc[ftest['images containing damage in the RRDR']==True, ['image file name', 'component label file name', 'damage label file name', 'depth image file name', 'camera focal length in mm']]\n"
      ],
      "metadata": {
        "id": "1XgKPvOXNE8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dataloader for component damage images\n",
        "\n",
        "images_test = test_comp['image file name'].to_numpy()\n",
        "masks_test = test_comp['damage label file name'].to_numpy()\n",
        "dataset_test = tf_dataset_test(images_test,masks_test)\n",
        "address = test_comp['damage label file name'].apply(lambda x : os.path.split(x)[1]).to_numpy()"
      ],
      "metadata": {
        "id": "_fCLyMqZNIdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing predictions on the component damage test dataset\n",
        "z=1\n",
        "for x, y in dataset_test.take(10):\n",
        "        z += 1\n",
        "        show_img(x[0])\n",
        "        show_label(y[0])\n",
        "        pred = model.predict(x)\n",
        "        show_pred(pred[0])\n",
        "        if (z==9):\n",
        "          break"
      ],
      "metadata": {
        "id": "LxfQEDWLNLdV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}